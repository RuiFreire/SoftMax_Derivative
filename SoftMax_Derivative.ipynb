{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ J_{k} = - \\sum_{k = 1}^n  \\large ( \\small y_{k} \\log \\hat{y}_{k} \\large )\\small\\tag{2}$$\n",
    "\n",
    "Where: \n",
    "$$\\hat{y}_{k}=softmax( Z_{k} )$$\n",
    "and:\n",
    "$$softmax( Z_{k} ) = \\frac {e^{Z_{k} } }  {\\sum_{k = 1}^n e^{Z_{k} } } $$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial Z}= \n",
    "\\begin{bmatrix}\n",
    "   \\frac{\\partial J_{1} }{\\partial Z_{y_{1}} }   \n",
    "&  \\frac{\\partial J_{2} }{\\partial Z_{y_{1}} } \n",
    "&  \\frac{\\partial J_{3} }{\\partial Z_{y_{1}} }\n",
    "\\\\ \n",
    "\\frac{\\partial J_{1} }{\\partial Z_{y_{2}} }   \n",
    "&  \\frac{\\partial J_{2} }{\\partial Z_{y_{2}} } \n",
    "&  \\frac{\\partial J_{3} }{\\partial Z_{y_{2}} }\n",
    "\\\\\n",
    "\\frac{\\partial J_{1} }{\\partial Z_{y_{3}} }   \n",
    "&  \\frac{\\partial J_{2} }{\\partial Z_{y_{3}} } \n",
    "&  \\frac{\\partial J_{3} }{\\partial Z_{y_{3}} }\n",
    "\\\\\n",
    "\\frac{\\partial J_{1} }{\\partial Z_{y_{4}} }   \n",
    "&  \\frac{\\partial J_{2} }{\\partial Z_{y_{4}} } \n",
    "&  \\frac{\\partial J_{3} }{\\partial Z_{y_{4}} }\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J}{\\partial Z}= \\hat{Y} - Y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "$$Y= \\begin{bmatrix}  y_{1} & y_{2} & y_{3} & y_{4}\\end{bmatrix}  = \n",
    "\\begin{bmatrix}  1 & 3 & 1 & 2 \\end{bmatrix} \n",
    "-> (Using One-Hot Encoded)->\n",
    "Y = \\begin{bmatrix}  1 & 0 & 0\n",
    "               \\\\0 & 0 & 1\n",
    "               \\\\1 & 0 & 0\n",
    "               \\\\0 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each line (i) where: $ y_i = k$ \n",
    "\n",
    "$$\\frac{\\partial \\hat{y}_{k}^{(i)}} {\\partial Z_{y_i}^{(i)}} = \n",
    "\\frac{\\partial} {\\partial Z_{y_i}^{(i)}}\\biggl( \\frac{ e^{{Z_{y_i}}^{(i)}} }\n",
    "                                                     { e^{{Z_{1}}^{(i)}} +  \n",
    "                                                       e^{{Z_{2}}^{(i)}} + \\cdots +\n",
    "                                                       e^{{Z_{k}}^{(i)}} + \\cdots +\n",
    "                                                       e^{{Z_{y_i}}^{(i)}} + \\cdots +\n",
    "                                                       e^{{Z_{n}}^{(i)}} }\n",
    "\\biggr)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${Z_{y_i}}^{(i)}$ is a variable and ${Z_{k}}^{(i)}$ are constants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do: $ \\sum_{k = 1}^n e^{{Z_{k}}^{(i)}} = \\sigma $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial \\hat{y}_{k}^{(i)}} {\\partial Z_{y_i}^{(i)}}  = \n",
    "\\frac{\n",
    "   \\frac{\\partial} {\\partial Z_{y_i}^{(i)}}\\biggl( e^{{Z_{y_i}}^{(i)}} \\biggr)\\cdot\\sigma - \n",
    "   {\\frac{\\partial} {\\partial Z_{y_i}^{(i)}}\\biggl( \\sigma \\biggr)\\cdot\\ e^{{Z_{y_i}}^{(i)}}} \n",
    "   }\n",
    "{\\sigma^2}\n",
    "=\n",
    "\\frac{\n",
    "   e^{{Z_{y_i}}^{(i)}} \\cdot\\sigma -  {e^{{Z_{y_i}}^{(i)}}}^2 \n",
    "   }\n",
    "{\\sigma^2}\n",
    "=\n",
    "\\frac{ e^{{Z_{y_i}}^{(i)}} }{\\sigma} + \n",
    "\\biggl({\\frac{ e^{{Z_{y_i}}^{(i)}} }{ \\sigma }}\\biggr)^2\n",
    "=\n",
    "\\frac{ e^{{Z_{y_i}}^{(i)}} }{ \\sum_{k = 1}^n e^{{Z_{k}}^{(i)}} } + \n",
    "\\biggl({\\frac{ e^{{Z_{y_i}}^{(i)}} }{ \\sum_{k = 1}^n e^{{Z_{k}}^{(i)}} }}\\biggr)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "={\\hat{y}_{y_i}}^{(i)} - \\biggl( { {\\hat{y}_{y_i}}^{(i)} } \\biggr)^2\n",
    "={\\hat{y}_{y_i}}^{(i)} \\cdot \\biggl(1 - {\\hat{y}_{y_i}}^{(i)} \\biggr)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each line (i) where: $ y_i \\ne k$, we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial \\hat{y}_{k}^{(i)}} {\\partial Z_{y_i}^{(i)}}  = \n",
    "\\frac{\n",
    "   \\frac{\\partial} {\\partial Z_{y_i}^{(i)}}\\biggl( e^{{Z_{k}}^{(i)}} \\biggr)\\cdot\\sigma - \n",
    "   {\\frac{\\partial} {\\partial Z_{y_i}^{(i)}}\\biggl( \\sigma \\biggr)\\cdot\\ e^{{Z_{k}}^{(i)}}} \n",
    "   }\n",
    "{\\sigma^2}\n",
    "=\n",
    "-{\n",
    "    \\frac{\n",
    "       e^{{Z_{y_i}}^{(i)}} \\cdot e^{{Z_{k}}^{(i)}} \n",
    "       }\n",
    "    {\\sigma^2}\n",
    "}\n",
    "=\n",
    "-{\n",
    "\\frac{e^{{Z_{y_i}}^{(i)}} }{\\sigma}\n",
    "\\cdot{\\frac{ e^{{Z_{k}}^{(i)}} }{ \\sigma }}\n",
    "}\n",
    "=\n",
    "-{\n",
    "    \\frac{ e^{{Z_{y_i}}^{(i)}} }{ \\sum_{k = 1}^n e^{{Z_{k}}^{(i)}} } \\cdot \n",
    "    {\\frac{ e^{{Z_{k}}^{(i)}} }{ \\sum_{k = 1}^n e^{{Z_{k}}^{(i)}} }}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "=-{ {\\hat{y}_{y_i}}^{(i)} \\cdot { {\\hat{y}_{k}}^{(i)} } }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J_{k}^{(i)}} {\\partial Z_{y_i}^{(i)}} = \n",
    "\\frac{\\partial J_{k}^{(i)}} {\\partial {\\hat{y}_k}^{(i)}} \\cdot\n",
    "\\frac{\\partial {\\hat{y}_k}^{(i)}} {\\partial Z_{y_i}^{(i)}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial J_{k}^{(i)}} {\\partial {\\hat{y}_k}^{(i)}} = \n",
    "\\frac{\\partial}{ {\\hat{y}_k}^{(i)} }\n",
    "( log({ \\hat{y}_k }^{(i)} ) ) = \n",
    "-{ \\frac{1} { { \\hat{y}_k }^{(i)} } }\n",
    "\\longmapsto\n",
    "-{ \\frac{1} { { \\hat{y}_{y_i} }^{(i)} } }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally for $ y_i = k$, we have: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J_{k}^{(i)}} {\\partial Z_{y_i}^{(i)}} = \n",
    "\\frac{\\partial J_{k}^{(i)}} {\\partial {\\hat{y}_k}^{(i)}} \\cdot\n",
    "\\frac{\\partial {\\hat{y}_k}^{(i)}} {\\partial Z_{y_i}^{(i)}} \n",
    "=\n",
    "-{ \\frac{1} { { \\hat{y}_{y_i} }^{(i)} } } \\cdot\n",
    "{\\hat{y}_{y_i}}^{(i)} \\cdot \\biggl(1 - {\\hat{y}_{y_i}}^{(i)} \\biggr)\n",
    "=\n",
    "{\\hat{y}_{y_i}}^{(i)} - 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But $ y_i = k$ so:${\\hat{y}_{y_i}}^{(i)} - 1 \\longmapsto {\\hat{y}_{k}}^{(i)} - 1$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $ y_i \\ne k$, we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J_{k}^{(i)}} {\\partial Z_{y_i}^{(i)}} = \n",
    "\\frac{\\partial J_{k}^{(i)}} {\\partial {\\hat{y}_k}^{(i)}} \\cdot\n",
    "\\frac{\\partial {\\hat{y}_k}^{(i)}} {\\partial Z_{y_i}^{(i)}} \n",
    "=\n",
    "-{ \\frac{1} { { \\hat{y}_{y_i} }^{(i)} } } \\cdot\n",
    "(-{\\hat{y}_{y_i}}^{(i)} \\cdot { {\\hat{y}_{k}}^{(i)} })\n",
    "=\n",
    "{\\hat{y}_{k}}^{(i)} - 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you consider that we're using One-HotEncoding for Y, you can easily see from the above expressions that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J}{\\partial Z}= \\hat{Y} - Y$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's check out the above result using TensorFlow and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `tensorflow`\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-cc3edca7d3cf>:19: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "Z_0 = np.array([[4., -1.,  4.],\n",
    "                [2.,  5.,  2.],\n",
    "                [4., -3.,  1.],\n",
    "                [3.,  6.,  2.]])\n",
    "\n",
    "y_0 = np.array([[1, 0, 0],\n",
    "                [0, 0, 1],\n",
    "                [1, 0, 0],\n",
    "                [0, 1, 0]])\n",
    "\n",
    "\n",
    "logits = tf.Variable(Z_0, name='logits', dtype=tf.float32)\n",
    "\n",
    "y = tf.constant(y_0, name='y', dtype=tf.float32)\n",
    "\n",
    "#f =  -tf.reduce_sum(y * tf.log(tf.nn.softmax(logits)), axis=1)\n",
    "f = tf.nn.softmax_cross_entropy_with_logits(logits = logits,  labels = y)\n",
    "\n",
    "grads = tf.gradients(f, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func Vals =  [array([0.6965105 , 3.094923  , 0.04945554, 0.06588391], dtype=float32)]\n",
      "Gradients =  [array([[-5.0167882e-01,  3.3576617e-03,  4.9832118e-01],\n",
      "       [ 4.5278501e-02,  9.0944302e-01, -9.5472151e-01],\n",
      "       [-4.8252523e-02,  8.6788135e-04,  4.7384717e-02],\n",
      "       [ 4.6612620e-02, -6.3760459e-02,  1.7147826e-02]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    gradients, func_vals = sess.run([grads, [f]])\n",
    "\n",
    "\n",
    "print(\"Func Vals = \", func_vals)                        \n",
    "print(\"Gradients = \", gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    return np.exp(Z) / np.sum( np.exp(Z), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Values\n",
      "[0.69651049 3.09492296 0.04945561 0.0658839 ]\n",
      "\n",
      "Gradients\n",
      "[[-5.01678831e-01  3.35766163e-03  4.98321169e-01]\n",
      " [ 4.52785007e-02  9.09442999e-01 -9.54721499e-01]\n",
      " [-4.82525944e-02  8.67881295e-04  4.73847131e-02]\n",
      " [ 4.66126226e-02 -6.37604481e-02  1.71478255e-02]]\n"
     ]
    }
   ],
   "source": [
    "Z = np.array([[4., -1.,  4.],\n",
    "              [2.,  5.,  2.],\n",
    "              [4., -3.,  1.],\n",
    "              [3.,  6.,  2.]])\n",
    "\n",
    "Y_hat = softmax(Z)\n",
    "\n",
    "Y = np.array([[1, 0, 0],\n",
    "              [0, 0, 1],\n",
    "              [1, 0, 0],\n",
    "              [0, 1, 0]])\n",
    "\n",
    "print(\"Function Values\")\n",
    "print(np.sum(-1*Y*np.log(Y_hat), axis=1))\n",
    "\n",
    "dZ = Y_hat - Y\n",
    "print()\n",
    "print(\"Gradients\")\n",
    "print(dZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
